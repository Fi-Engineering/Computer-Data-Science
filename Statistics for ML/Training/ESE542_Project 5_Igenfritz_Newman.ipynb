{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5\n",
    "\n",
    "In addition to answering the bolded questions on Coursera, also attach your notebook, both as\n",
    "`.ipynb` and `.html`.\n",
    "\n",
    "In the following exercise, we will perform bootstrap and cross validation to find statistical values for two datasets.\n",
    "\n",
    "In this assignment, we will be using PennGrader, a Python package built by a former TA for autograding Python notebooks. PennGrader was developed to provide students with instant feedback on their answer. You can submit your answer and know whether it's right or wrong instantly. We then record your most recent answer in our backend database. You will have 100 attempts per test case, which should be more than sufficient.\n",
    "\n",
    "<b>NOTE：Please remember to remove the </b>\n",
    "\n",
    "```python\n",
    "raise notImplementedError\n",
    "```\n",
    "<b>after your implementation, otherwise the cell will not compile.</b>\n",
    "\n",
    "\n",
    "A few things to note before we start\n",
    "- You do not have to round your answers.\n",
    "- Please make sure your answer's variable name do match what is provided in grader cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Setup\n",
    "Please run the below cells to get setup with the autograder. If you need to install packages, please do it below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install penngrader --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn --user\n",
    "# !pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try PennGrader out! Fill in the cell below with your PennID and then run the following cell to initialize the grader.\n",
    "\n",
    "<font color='red'>Warning:</font> Please make sure you only have one copy of the student notebook in your directory in Codio upon submission. The autograder looks for the variable `STUDENT_ID` across all notebooks, so if there is a duplicate notebook, it will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLEASE ENSURE YOUR STUDENT_ID IS ENTERED AS AN INT (NOT A STRING). IF NOT, THE AUTOGRADER WON'T KNOW WHO \n",
    "#TO ASSIGN POINTS TO YOU IN OUR BACKEND\n",
    "\n",
    "STUDENT_ID = 49731093                   # YOUR 8-DIGIT PENNID GOES HERE\n",
    "STUDENT_NAME = \"Newman Ilgenfritz\"     # YOUR FULL NAME GOES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import penngrader.grader\n",
    "\n",
    "grader = penngrader.grader.PennGrader(homework_id = 'ESE542_Online_Spring_2021_HW5', student_id = STUDENT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "First, we will use the Boston dataset to try running our own implementation of bootstrap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Logistic Regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Cross Validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Statistics\n",
    "from scipy import stats\n",
    "\n",
    "RANDOM_STATE=42\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()\n",
    "data = pd.DataFrame(data = boston_dataset.data, columns = boston_dataset.feature_names)\n",
    "data['MEDV'] = pd.Series(boston_dataset.target)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Based on this dataset, provide an estimate for $\\hat\\mu$, the population mean of 'medv'. Name this variable `mu_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110677"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter your code below\n",
    "\n",
    "mu_hat = data['MEDV'].mean()\n",
    "mu_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_mu_hat', answer = mu_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Provide an estimate of the standard error of $\\hat\\mu$. Name this variable `se_mu_hat`>. Interpret this result in your Jupyter notebook. \n",
    "\n",
    "*Hint*: We can compute the standard error of the sample mean by dividing the <u>sample</u> standard deviation by the square root of the number of observations. When computing the sample standard deviation, one must consider the Bessel’s correction factor from statistics (more information on that [here](https://en.wikipedia.org/wiki/Bessel\\%27s_correction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4092657603105486"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "sd = data['MEDV'].std()\n",
    "se_mu_hat = sd / math.sqrt(len(data)-1) # -1 Bessel correction\n",
    "se_mu_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_se_mu_hat', answer = se_mu_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now estimate the standard error of  by implementing your own bootstrap method. Name your final answer `se_boostrap`. How does this compare to your answer from Part A Question 2? \n",
    "\n",
    "*Hint*: Generate $M=n$ artificial datasets, each with $N=n$ bootstrap samples. Use `np.random.seed(RANDOM_STATE)` before sampling so that your outputs stay consistent. You should try to write your own bootstrap method and and then compare it to packages such as SKLearn's `resample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  506 \n",
      "\n",
      "muSamp:  22.529964145667016 \n",
      "\n",
      "se_bootstrap:  0.40631291586573504 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "n = data.shape[0]\n",
    "print('n: ', n, '\\n')\n",
    "\n",
    "sampSize = n\n",
    "samp = np.random.choice(data['MEDV'], size=sampSize, replace=True)\n",
    "\n",
    "muSamp = samp.mean()\n",
    "sdSamp = samp.std()\n",
    "\n",
    "se = sdSamp/math.sqrt(len(samp)-1)\n",
    "\n",
    "iterations = sampSize\n",
    "means = []\n",
    "for sets in range(iterations):\n",
    "     \n",
    "     samp = np.random.choice(data['MEDV'], size=sampSize, replace=True)\n",
    "     means.append(np.mean(samp))\n",
    "\n",
    "\n",
    "means.sort()\n",
    "\n",
    "muSamp = np.asarray(means).mean()\n",
    "print('muSamp: ', muSamp, '\\n')\n",
    "\n",
    "se_bootstrap = np.asarray(means).std(ddof=1)\n",
    "print('se_bootstrap: ',se_bootstrap , '\\n')\n",
    "\n",
    "p = 0.95\n",
    "\n",
    "u_pval = (1+p)/2.\n",
    "l_pval = (1-u_pval)\n",
    "l_indx = int(np.floor(n*l_pval))\n",
    "u_indx = int(np.floor(n*u_pval))\n",
    "\n",
    "ciTup = (means[l_indx], means[u_indx])\n",
    "ciL = muSamp - (2*se_bootstrap)\n",
    "ciU = muSamp + (2*se_bootstrap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 2/2 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_se_bootstrap', answer = se_bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Based on your bootstrap estimate from Part A Question 3, provide a $95\\%$ confidence interval for the mean of 'medv'. Enter the lower range, higher range for mean's confidence interval in CI_lower, CI_upper.\n",
    "\n",
    "*Hint*: You can approximate a $95\\%$ confidence interval using the formula $[\\hat\\mu \\pm 2 * SE(\\hat\\mu)] $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_lower = ciL\n",
    "CI_upper = ciU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.0/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_CI_mean', answer = (CI_lower, CI_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Based on this data set, provide the population median value of 'medv', $\\widehat{median}$. Name this variable `median_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_hat = data['MEDV'].median()\n",
    "median_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_median_hat', answer = median_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. We now would like to estimate the standard error of $\\widehat{median}$. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using bootstrap. Name this variable `se_bootstrap_median`.\n",
    "\n",
    "*Hint*: use your bootstrap sample list from A.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = []\n",
    "for sets in range(iterations):\n",
    "    \n",
    "     samp = np.random.choice(data['MEDV'], size=sampSize, replace=True)\n",
    "     medians.append(np.median(samp))\n",
    "\n",
    "medians.sort()\n",
    "\n",
    "muSamp = np.asarray(medians).mean()\n",
    "\n",
    "se_bootstrap_median = np.asarray(means).std(ddof=1)\n",
    "\n",
    "p = 0.95\n",
    "\n",
    "u_pval = (1+p)/2.\n",
    "l_pval = (1-u_pval)\n",
    "l_indx = int(np.floor(n*l_pval))\n",
    "u_indx = int(np.floor(n*u_pval))\n",
    "\n",
    "ciTup = (means[l_indx], means[u_indx])\n",
    "ciL = muSamp - (2*se_bootstrap)\n",
    "ciU = muSamp + (2*se_bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_se_median', answer = se_bootstrap_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.  Is the standard error of the median greater or less than the standard error of the mean?Does this make intuitive sense? Comment on your other findings in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard error of median is greater than standard error of mean\n"
     ]
    }
   ],
   "source": [
    "delta = se_bootstrap - se_bootstrap_median\n",
    "delta\n",
    "if(delta>0):\n",
    "    print('standard error of mean is greater than standard error of median')\n",
    "else:\n",
    "    print('standard error of median is greater than standard error of mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "Next, we will use the Default dataset to predict the probability of default using income and balance. In doing so, we also want to estimate the test error of the logistic regression model described in that section using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default  student      balance        income\n",
       "0        0        0   729.526495  44361.625074\n",
       "1        0        1   817.180407  12106.134700\n",
       "2        0        0  1073.549164  31767.138947\n",
       "3        0        0   529.250605  35704.493935\n",
       "4        0        0   785.655883  38463.495879"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default = pd.read_csv('Default.csv')\n",
    "encode = lambda x: 1 if x == 'Yes' else 0\n",
    "default['default'] = default['default'].map(encode)\n",
    "default['student'] = default['student'].map(encode)\n",
    "default.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit a logistic regression model that use <u>all</u> the data from the predictors 'income' and 'balance' to predict 'default'. Please name your model <b>fit1</b>.\n",
    "\n",
    "*Hint*: Use `Stats Models` to fit the logistic regression. Review the previous recitations for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                10000\n",
      "Model:                            GLM   Df Residuals:                     9997\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -789.48\n",
      "Date:                Wed, 24 Feb 2021   Deviance:                       1579.0\n",
      "Time:                        16:48:53   Pearson chi2:                 6.95e+03\n",
      "No. Iterations:                     9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
      "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
      "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
      "============================================================================== \n",
      "\n",
      "Predicted probability of default: [1.50472802e-03 1.26192994e-03 8.02621054e-03 ... 3.88716068e-03\n",
      " 1.28189088e-01 4.29711151e-05] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit1 = smf.glm('default~balance+income', data = default, family=sm.families.Binomial()).fit()\n",
    "print(fit1.summary(), '\\n')\n",
    "print('Predicted probability of default:',fit1.predict(), '\\n') #Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_glm_type', answer = str(type(fit1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 2/2 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_glm', answer = fit1.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps: \n",
    "\n",
    "\n",
    "- Split the sample set into a random training set and a random validation set. Use a test size of 20%. *Hint*: Use `sklearn.model_selection.train_test_split` and a `random_state` of 42/RANDOM_STATE. Store your training set in <b>train</b>, testing set in <b>test</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train head: \n",
      "      default  student      balance        income\n",
      "9254        0        0  1018.568130  34103.879520\n",
      "1561        0        0    62.170050  28660.747508\n",
      "1670        0        0  1046.743543  40822.447413\n",
      "6087        0        0   763.735280  44125.718725\n",
      "6669        0        1   697.248633  25730.917583 \n",
      "\n",
      "test head: \n",
      "      default  student      balance        income\n",
      "6252        0        0  1435.662933  31507.089277\n",
      "4684        0        0   771.789347  42139.070269\n",
      "1731        0        0     0.000000  21809.218509\n",
      "4742        0        0   113.571264  32803.832648\n",
      "4521        0        0  1358.132472  49903.597081 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train, test = train_test_split(default, test_size=0.20, random_state=RANDOM_STATE)\n",
    "print('train head: ')\n",
    "print(train.head(), '\\n')\n",
    "print('test head: ')\n",
    "print(test.head(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_train_shape', answer = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_test_shape', answer = test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit a logistic regression with multiple variables model using <u>only</u> the training observations. Name your model <b>fit2</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                 8000\n",
      "Model:                            GLM   Df Residuals:                     7997\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -609.84\n",
      "Date:                Wed, 24 Feb 2021   Deviance:                       1219.7\n",
      "Time:                        16:49:03   Pearson chi2:                 6.64e+03\n",
      "No. Iterations:                     9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -11.8297      0.506    -23.387      0.000     -12.821     -10.838\n",
      "balance        0.0058      0.000     22.038      0.000       0.005       0.006\n",
      "income      2.075e-05   5.64e-06      3.682      0.000    9.71e-06    3.18e-05\n",
      "============================================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_equation = 'default~balance+income'\n",
    "fit2 = smf.glm(logit_equation, data = train, family=sm.families.Binomial()).fit()\n",
    "print(fit2.summary(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_glm_type', answer = str(type(fit2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.0/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_train_para', answer = fit2.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obtain a prediction of 'default' for each individual in the test set by computing the probability of default for that individual and classifying the individual to the default category if the posterior probability is greater than or equal to 0.5 (a Bayesian classifier). Store your predictions in <b>predicted</b>.\n",
    "\n",
    "*Hint*: we check for both the size and values of your precitions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtest.head: \n",
      "          balance        income\n",
      "6252  1435.662933  31507.089277\n",
      "4684   771.789347  42139.070269\n",
      "1731     0.000000  21809.218509\n",
      "4742   113.571264  32803.832648\n",
      "4521  1358.132472  49903.597081 \n",
      "\n",
      "Xtest size:  2000 \n",
      "\n",
      "mis_rate: \n",
      "0.005 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter your code below\n",
    "#print('Predicted probability of default:',fit2.predict(), '\\n') #Predict\n",
    "Xtest = pd.DataFrame()\n",
    "Xtest['balance'] = test['balance']\n",
    "Xtest['income'] = test['income']\n",
    "print('Xtest.head: ')\n",
    "print(Xtest.head(), '\\n')\n",
    "print('Xtest size: ', len(Xtest), '\\n')\n",
    "\n",
    "#encode = lambda x: 1 if x == 'Yes' else 0\n",
    "ytest = test['default']\n",
    "yprobs = fit2.predict(Xtest)\n",
    "yPred =  [0 if y < 0.5 else 1 for y in yprobs]\n",
    "\n",
    "predicted = np.asarray(yPred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "x = confusion_matrix(ytest, yPred)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "aScore = accuracy_score(ytest, yPred)\n",
    "\n",
    "\n",
    "fraction_correct_test = aScore\n",
    "\n",
    "# Your answer should be the ratio of number of correct predictions over the total number of samples.\n",
    "#mis_rate = 1.0 - aScore\n",
    "\n",
    "#mis_rate = float(28/2000)\n",
    "mis_rate = x[0,1]/len(predicted)\n",
    "\n",
    "print('mis_rate: ')\n",
    "print(mis_rate, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "#raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.0/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_glm_predict', answer = predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the misclassification rate, which is the fraction of the observations in the validation set that are misclassified. Name this variable `mis_rate` and. \n",
    "\n",
    "*Hint*: Compare the predictions with the test set. Your answer should be the ratio of number of correct predictions over the total number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate = 1-aScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_mis_rate', answer = mis_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Repeat the process in Part B Question 2 three times, using three different splits of the observations into a training set and a validation set. Use test sizes of $10\\%$, $30\\%$, and $50\\%$. Name the misclassification rates `mis_rate_10`, `mis_rate_30`, `mis_rate50`, respectively. Comment on the results obtained and determine the key takeaway. Store the accuracy score for each model within <b>model_rates</b> and model parameters within <b>model_params</b>\n",
    "\n",
    "*Note*: When splitting to test/train sets, please set your random_state to RANDOM_STATE so that you can have the same group of testing and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_rates: \n",
      "[0.03300000000000003, 0.026666666666666616, 0.025800000000000045] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "testSize10 = 0.10\n",
    "testSize30 = 0.30\n",
    "testSize50 = 0.50\n",
    "testList = [testSize10, testSize30, testSize50]\n",
    "fitList = []\n",
    "predict = []\n",
    "aScore = []\n",
    "mis_rate = []\n",
    "model_rates = []\n",
    "\n",
    "for i in range(3):\n",
    "    train, test= train_test_split(default, test_size=testList[i], random_state=RANDOM_STATE)\n",
    "    fitList.append(smf.glm(logit_equation, data = train, family=sm.families.Binomial()).fit())\n",
    "    Xtest = pd.DataFrame()\n",
    "    Xtest['balance'] = test['balance']\n",
    "    Xtest['income'] = test['income']\n",
    " \n",
    "    ytest = test['default']\n",
    "    \n",
    "    yprobs = fitList[i].predict(Xtest)\n",
    "   \n",
    "    yPred =  [0 if y < 0.5 else 1 for y in yprobs]\n",
    "\n",
    "    predict.append(np.asarray(yPred))\n",
    "  \n",
    "    x = confusion_matrix(ytest, yPred)\n",
    "    \n",
    "    aScore.append(accuracy_score(ytest, yPred))\n",
    "\n",
    "    mis_rate.append(1.0 - aScore[i])\n",
    "\n",
    "model_rates = mis_rate\n",
    "print('model_rates: ')\n",
    "print(model_rates, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 2.0/2 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_models_rates', answer = model_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using KFold cross validation with five folds across 5 trials, calculate the <b>average</b> misclassification rate. Name this `mis_rate_kfold`. In your notebook, briefly explain the KFold process. \n",
    "\n",
    "*Hint*: Because `Stats Models` does not have its own cross validation libraries, you may have to use the following packages (specify a `random_state` equaling the trial number(5)): \n",
    "\n",
    "\n",
    "- `sklearn.linear_model.LogisticRegression`\n",
    "- `sklearn.model_selection.cross_val_score`\n",
    "- `sklearn.model_selection.KFold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mis_rate_kfold:  0.028244708096504846 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "blue = '#008FD5'\n",
    "red = '#FF2700'\n",
    "green = '#77AB43'\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def poly(x, p):\n",
    "    x = np.array(x)\n",
    "    X = np.transpose(np.vstack([x**k for k in range(p+1)]))\n",
    "    return np.linalg.qr(X)[0][:,1:]\n",
    "\n",
    "X = pd.DataFrame()\n",
    "X['balance'] = default['balance']\n",
    "X['income']  = default['income']\n",
    "\n",
    "y = default['default']\n",
    "\n",
    "model = LinearRegression() #Define ML Model\n",
    "\n",
    "score = np.array([])# array to store errors\n",
    "order = np.array([]) # array to store order of polynomial\n",
    "trials = 5\n",
    "splits = 10\n",
    "\n",
    "\n",
    "for trial in range(trials):\n",
    "    cv_method = KFold(n_splits=splits,shuffle=True,random_state = trials) #Define CV method\n",
    "    error = -1*np.mean(cross_val_score(model,X,y,cv = cv_method,scoring = 'neg_mean_squared_error'))\n",
    "    score = np.append(score, error)\n",
    "\n",
    "mis_rate_kfold = score.mean()\n",
    "print('mis_rate_kfold: ',mis_rate_kfold ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_mis_kfold', answer = mis_rate_kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using bootstrap on the complete dataset, compute estimates for the standard errors of the `income` and `balance` logistic regression coefficients. In order to do this, you should perform the following steps:\n",
    "\n",
    "\n",
    "- Write a function that takes as input the Default data set (and optionally, an index of the observations). The method should be called `boot_sample(data,index)`. The method should return the coefficient estimates for income and balance in the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_sample(data, index):\n",
    "    \n",
    "    return resample(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Use this function to estimate the standard errors of the logistic regression coefficients for income and balance using 100 different bootstrap samples. Store your lists of results in boot_income, boot_balance, both of lists should be of size (100,1). \n",
    "*Note*: Do not set a random seed in this problem, otherwise you will not be randomly sample from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "length = 100\n",
    "boot_income = np.array([])\n",
    "boot_balance = np.array([])\n",
    "\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "\n",
    "intercept = []\n",
    "income = []\n",
    "balance = []\n",
    "\n",
    "index = 0\n",
    "for trial in range(length):\n",
    "    train = boot_sample(default, index)\n",
    "    X = train[['income', 'balance']]\n",
    "    X = sm.add_constant(X, prepend=True)\n",
    "    y = train['default']\n",
    "\n",
    "    model = Logit(y, X)\n",
    "    result = model.fit(disp=False)\n",
    "    intercept.append(result.params.const)\n",
    "    income.append(result.params.income)\n",
    "    balance.append(result.params.balance)\n",
    "\n",
    "boot_balance = balance\n",
    "boot_income = income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 2/2 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id ='test_boot_income_balance', answer = (boot_income, boot_balance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comment on the estimated standard errors obtained. What are the confidence intervals of the logistic regression coefficients? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Estimated SEs indicate high confidence there is a significant relationship\\n    between default rates and both balance and income \\n    \\n    confidence intervals:\\n           balance:     0.005      0.006\\n           income:      1.1e-05    3.06e-05\\n\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Estimated SEs indicate high confidence there is a significant relationship\n",
    "    between default rates and both balance and income \n",
    "    \n",
    "    confidence intervals:\n",
    "           balance:     0.005      0.006\n",
    "           income:      1.1e-05    3.06e-05\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on making the end of project 5. Please remember to save a copy of .ipynb and .html of your notebook, and mark your project as complete on Codio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
